{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e2c6f0",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3931b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml-related things\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# typing\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from pandas.core.frame import DataFrame\n",
    "from scipy.sparse.csr import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c801a",
   "metadata": {},
   "source": [
    "Data processing functions and pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c5d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename: str) -> DataFrame:\n",
    "    \"\"\" Read parquet data and add duration in minutes\"\"\"\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    # get duration in minutes\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    return df\n",
    "\n",
    "def remove_outliers(df: DataFrame, t_min: int=1, t_max: int=60) -> DataFrame:\n",
    "    \"\"\" Remove duration outliers\"\"\"\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    return df\n",
    "\n",
    "def fill_na(df: DataFrame, columns: List[str]) -> DataFrame:\n",
    "    \"\"\" Replace NaN with -1 \"\"\"\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna(-1)\n",
    "    return df\n",
    "\n",
    "def one_hot_encoding(df: DataFrame, columns: List[str], target: str='duration', mode: str='train', dv: DictVectorizer=DictVectorizer()) -> Tuple[csr_matrix, np.array, DictVectorizer]:\n",
    "    \"\"\" \n",
    "    One hot encoding for categorical variables.\n",
    "    + prepare ground truth data \n",
    "    \"\"\"\n",
    "    \n",
    "    df[columns] = df[columns].astype(str)\n",
    "\n",
    "    # records dictionaries\n",
    "    rec_dicts = df[columns].to_dict(orient='records')\n",
    "    \n",
    "    # === Train or Predict modes === #\n",
    "    if mode=='train':\n",
    "        # Learn a list of feature name -> indices mappings and transform X.\n",
    "        X = dv.fit_transform(rec_dicts)\n",
    "        y = df[target].values\n",
    "        return X, y, dv\n",
    "    \n",
    "    else:\n",
    "        # Transform feature -> value dicts to array or sparse matrix.\n",
    "        X = dv.transform(rec_dicts)\n",
    "        y = df[target].values\n",
    "        return X, y, dv \n",
    "\n",
    "def data_process(filename: str, mode: str, dv: DictVectorizer=DictVectorizer()) -> Tuple[csr_matrix, np.array]:\n",
    "    \"\"\" Complete data processing pipeline\"\"\"\n",
    "    df = read_data(filename)\n",
    "    df = remove_outliers(df)\n",
    "    \n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "    df = fill_na(df, categorical)\n",
    "    X, y, dv = one_hot_encoding(df, categorical, 'duration', mode, dv)\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1371a4",
   "metadata": {},
   "source": [
    "ML model functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "500929d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR(X: csr_matrix, y: np.array) -> LinearRegression:\n",
    "    \"\"\" \"\"\"\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    return lr\n",
    "\n",
    "def predict_LR(lr: LinearRegression, X: csr_matrix, y: np.array) -> float:\n",
    "    \"\"\" \"\"\"\n",
    "    y_pred = lr.predict(X)\n",
    "\n",
    "    mse = mean_squared_error(y, y_pred, squared=False)\n",
    "    return round(mse,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f07afa",
   "metadata": {},
   "source": [
    "## Q1. Downloading the data\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page),\n",
    "but instead of \"Green Taxi Trip Records\", we'll use \"For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Download the data for January and February 2021.\n",
    "\n",
    "Note that you need \"For-Hire Vehicle Trip Records\", not \"High Volume For-Hire Vehicle Trip Records\".\n",
    "\n",
    "Read the data for January. **How many records are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393fd946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows is 1154112\n"
     ]
    }
   ],
   "source": [
    "df = read_data('./data/fhv_tripdata_2021-01.parquet')\n",
    "\n",
    "N_full = len(df)\n",
    "\n",
    "print(f'Total number of rows is {N_full}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94353e0c",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "\n",
    "Now let's compute the `duration` variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "**What's the average trip duration in January?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f113ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trip duration is 19.17\n"
     ]
    }
   ],
   "source": [
    "print(f'Average trip duration is {round(df.duration.mean(),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ccba0",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Check the distribution of the duration variable. There are some outliers.\n",
    "\n",
    "Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "**How many records did you drop?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3f3580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We removed 44286 data outliers\n"
     ]
    }
   ],
   "source": [
    "df = remove_outliers(df)\n",
    "\n",
    "N_select = len(df)\n",
    "\n",
    "print(f'We removed {N_full-N_select} data outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670cadd",
   "metadata": {},
   "source": [
    "## Q3. Missing values\n",
    "\n",
    "The features we'll use for our model are the pickup and dropoff location IDs.\n",
    "\n",
    "But they have a lot of missing values there. Let's replace them with \"-1\".\n",
    "\n",
    "**What's the fractions of missing values for the pickup location ID?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a80a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fractions of missing values for the pickup location ID is 83.53\n"
     ]
    }
   ],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "df = fill_na(df, categorical)\n",
    "\n",
    "rate_nan = round(df.PUlocationID.value_counts(normalize=True).iloc[0]*100.,2)\n",
    "print(f'The fractions of missing values for the pickup location ID is {rate_nan}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696260bd",
   "metadata": {},
   "source": [
    "## Q4. One-hot encoding\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "* Turn the dataframe into a list of dictionaries\n",
    "* Fit a dictionary vectorizer\n",
    "* Get a feature matrix from it\n",
    "\n",
    "**What's the dimensionality of this matrix?** (The number of columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194fdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensionality of the feature matrix is (1109826, 525)\n",
      "Number of columns is 525\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, dv = one_hot_encoding(df, categorical, target='duration', mode='train')\n",
    "\n",
    "print(f'The dimensionality of the feature matrix is {X_train.shape}')\n",
    "print(f'Number of columns is {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14951b94",
   "metadata": {},
   "source": [
    "## Q5. Training a model\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "* Train a plain linear regression model with default parameters\n",
    "* Calculate the RMSE of the model on the training data\n",
    "\n",
    "**What's the RMSE on train?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b6ea67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train is 10.53\n"
     ]
    }
   ],
   "source": [
    "model = train_LR(X=X_train, y=y_train)\n",
    "metric = predict_LR(model, X_train, y_train)\n",
    "\n",
    "print(f'RMSE on train is {metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78e5fb",
   "metadata": {},
   "source": [
    "## Q6. Evaluating the model\n",
    "\n",
    "Now let's apply this model to the validation dataset (Feb 2021).\n",
    "\n",
    "**What's the RMSE on validation?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f21c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = data_process('./data/fhv_tripdata_2021-02.parquet', 'test', dv)\n",
    "\n",
    "metric = predict_LR(model, X_test, y_test)\n",
    "\n",
    "print(f'RMSE on train is {metric}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
